{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# TD 04 GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# torch stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération des données\n",
    "\n",
    "- un cercle de rayon 3 centré en (0,0)\n",
    "- une sinusoide d'amplitude 1 et de fréquence 6 $\\pi$\n",
    "- une bande délimitée par deux  sinusoïdes (répartition graduelle en tanh)\n",
    "\n",
    "\n",
    "Les données seront légerement perturbées par un bruit gaussien d'amplitude 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return N data drawn according to the wanted density\n",
    "def f_data(N, model='circle'):\n",
    "  eps = np.random.randn(N) # Gaussian noise\n",
    "  if model == 'circle':\n",
    "    t = np.random.rand(N) # Uniform\n",
    "    return np.column_stack((TODO,TODO))\n",
    "\n",
    "  z1 = 3*np.random.randn(N) # Gaussian\n",
    "  if model == 'simple_sin':\n",
    "    return np.column_stack((TODO,TODO))\n",
    "  elif model == 'double_sin':\n",
    "    z2 = 3*np.random.randn(N) # Gaussian (2)\n",
    "    return np.column_stack((z1+0.1*eps,np.cos(z1)+np.tanh(z2)+0.1*eps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design des réseaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Générateur, il doit être en mesure de produire des données pour notre problème.\n",
    "\n",
    "Première couche est l'espace du latent `sz_latent`, une couche cachée de taille `sz_hidden` et une couche de sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "  def __init__(self, sz_latent,sz_hidden):\n",
    "    super(Generator, self).__init__()\n",
    "    self.fc1 = nn.Linear(TODO,TODO)\n",
    "    self.fc2 = nn.Linear(TODO,TODO)\n",
    "    self.fout = nn.Linear(TODO,TODO)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fout(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le réseau critique, est un MLP qui doit déterminer si les données sont réelles ou fausses.\n",
    "\n",
    "Il comporte trois couches, la première étant de taille `sz`. La taille des deux couches suivantes est deux fois moindre que sa précédente. La décision finale est la probabilité que la donnée d’entrée soit réelle (ou fake)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "  def __init__(self, sz):\n",
    "    super(Discriminator, self).__init__()\n",
    "    self.fc1 = nn.Linear(TODO,sz)\n",
    "    self.fc2 = nn.Linear(sz,TODO)\n",
    "    self.fc3 = nn.Linear(int(sz/2),TODO)\n",
    "    self.fout = nn.Linear(int(sz/4),TODO)\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = F.relu(self.fc3(x))\n",
    "    x = TODO # decision (proba)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(v):\n",
    "    return v.data.storage().tolist()\n",
    "\n",
    "def train(batch_size, model, device, G, D, criterion, d_optimizer, g_optimizer, latent_dim, epochs):\n",
    "  for epoch in range(epochs):\n",
    "      for ii in range(20):  # train D for 20 steps\n",
    "        D.zero_grad() # could be d_optimizer.zero_grad() since the optimizer is specific to the model\n",
    "\n",
    "        # train D on real data\n",
    "        d_real_data = (torch.FloatTensor(f_data(batch_size,model))).to(device)\n",
    "        d_real_decision = D(d_real_data)\n",
    "        d_real_error = criterion(d_real_decision, torch.TODO([batch_size,1]).to(device))\n",
    "        d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "        # train D on fake data\n",
    "        d_gen_seed = (torch.FloatTensor( torch.randn(batch_size,latent_dim ) )).to(device)  # TODO rand ou randn ?\n",
    "        d_fake_data = G( d_gen_seed ).detach()  # detach to avoid training G on these labels\n",
    "        d_fake_decision = D(d_fake_data)\n",
    "        d_fake_error = criterion(d_fake_decision, torch.TODO([batch_size,1]).to(device))\n",
    "        d_fake_error.backward()\n",
    "        d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "        dre, dfe = extract(d_real_error)[0], extract(d_fake_error)[0]\n",
    "\n",
    "      for ii in range(20):  # train G for 20 steps\n",
    "        G.zero_grad()\n",
    "\n",
    "        g_gen_seed = (torch.FloatTensor( torch.randn(batch_size,latent_dim ))).to(device)\n",
    "        g_fake_data = G( g_gen_seed )\n",
    "        dg_fake_decision = D(g_fake_data)\n",
    "        g_error = criterion(dg_fake_decision, torch.TODO([batch_size,1]).to(device))  # Train G to pretend it's genuine\n",
    "\n",
    "        g_error.backward()\n",
    "        g_optimizer.step()  # Only optimizes G's parameters\n",
    "\n",
    "        ge = extract(g_error)[0]\n",
    "      if epoch % 20 ==0:\n",
    "        print(\"Epoch %s: D (%1.4f real_err, %1.4f fake_err) G (%1.4f err) \" % (epoch, dre, dfe, ge))\n",
    "\n",
    "      if epoch % 60 == 0:\n",
    "        g_gen_seed = (torch.FloatTensor( torch.randn(1000,latent_dim ))).to(device)\n",
    "        g_fake_data = G( g_gen_seed ).detach().to(\"cpu\")\n",
    "        \n",
    "\n",
    "        # plot ground truth\n",
    "        if model == \"circle\":\n",
    "          t=np.arange(0,1.1,0.025)\n",
    "          plt.plot(3*np.cos(t*2*np.pi),3*np.sin(t*2*np.pi), 'r-')\n",
    "        if model == \"simple_sin\":\n",
    "          xx = np.arange(-3,3,0.25)\n",
    "          plt.plot(3*xx,np.cos(3*xx), 'r-')\n",
    "        if model == \"double_sin\":\n",
    "          xx = np.arange(-3,3,0.25)\n",
    "          plt.plot(3*xx,np.cos(3*xx)+1, 'r-')\n",
    "          plt.plot(3*xx,np.cos(3*xx)-1, 'r-')\n",
    "\n",
    "        plt.plot(g_fake_data[:,0],g_fake_data[:,1],'b.')\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_params_training(latent_dim = 2):\n",
    "    G = Generator(latent_dim,32).to(device)\n",
    "    D = Discriminator(32).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    d_optimizer = optim.SGD(TODO, lr=1e-3, momentum=0.8)\n",
    "    g_optimizer = optim.SGD(TODO, lr=1e-3, momentum=0.8)\n",
    "    # Adam optimizer\n",
    "    #d_optimizer = optim.TODO(TODO, lr=1e-3, TODO)\n",
    "    #g_optimizer = optim.TODO(TODO, lr=1e-3, TODO)\n",
    "    return G, D, criterion, d_optimizer, g_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"circle\"\n",
    "# model = \"simple_sin\"\n",
    "# model = \"double_sin\"\n",
    "latent_dim = 2\n",
    "# epochs = 3000\n",
    "epochs = 2000\n",
    "batch_size = 32\n",
    "G, D, criterion, d_optimizer, g_optimizer = get_params_training(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(batch_size, model, device, G, D, criterion, d_optimizer, g_optimizer, latent_dim, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Que se passe t'il si l'on réduit la dimension de l'espace latent ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = \"circle\"\n",
    "# model = \"simple_sin\"\n",
    "model = \"double_sin\"\n",
    "latent_dim = 1\n",
    "epochs = 3000\n",
    "# epochs = 2000\n",
    "G, D, criterion, d_optimizer, g_optimizer = get_params_training(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(batch_size, model, device, G, D, criterion, d_optimizer, g_optimizer, latent_dim, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
